{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e80e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 07:38:04.157058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-04 07:38:04.305893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-04 07:38:04.305926: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-03-04 07:38:05.217185: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-04 07:38:05.217315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-04 07:38:05.217330: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from moviepy.editor import VideoFileClip\n",
    "from feature_extractor import compute_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f27f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae87abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44183ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    def __init__(self, file_path, compute_audio):\n",
    "        self.file_path = file_path\n",
    "        self.audio = None\n",
    "        self.sr = None\n",
    "        self.segments = []\n",
    "        self.features = []\n",
    "        self.predictions = []\n",
    "        self.summary = None\n",
    "        self.compute_audio = compute_audio\n",
    "        self.output_folder = 'temporary'\n",
    "\n",
    "        \n",
    "    def check_format(self):\n",
    "        # Define acceptable video and audio formats\n",
    "        video_formats = ('.mp4', '.avi', '.mkv', '.mov', '.flv', '.wmv')\n",
    "        audio_formats = ('.mp3', '.wav', '.aac', '.flac', '.ogg', '.m4a', '.wma')\n",
    "\n",
    "        # Check if the file is a valid video or audio format\n",
    "        if self.file_path.endswith(audio_formats) or self.file_path.endswith(video_formats):\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('File not in a support data type. Please ensure you upload an audio',\n",
    "                             'or video, with mp3, wav, acc, flac, ogg, mp4, avi, or mkv formats.') \n",
    "        \n",
    "\n",
    "    def convert_video_to_audio(self):\n",
    "        # If the file is a video, convert to audio\n",
    "        if self.file_path.endswith(('.mp4', '.avi', '.mkv')):\n",
    "            audio_path = self.file_path.replace('.mp4', '.wav').replace('.mkv', '.wav').replace('.avi', '.wav')\n",
    "            clip = VideoFileClip(self.file_path)\n",
    "            clip.audio.write_audiofile(audio_path)\n",
    "            self.file_path = audio_path\n",
    "\n",
    "    def segment_audio(self):\n",
    "        # Load audio and split into 30-second segments\n",
    "        #self.segments = [self.file_path]\n",
    "        # Load audio file\n",
    "        self.audio, self.sr = librosa.load(self.file_path, sr=None)\n",
    "        \n",
    "        # Duration of a 30-second segment in samples\n",
    "        segment_length = 30 * self.sr\n",
    "        \n",
    "        # Split audio into segments\n",
    "        self.segments = [\n",
    "            self.audio[i:i + segment_length]\n",
    "            for i in range(0, len(self.audio), segment_length)\n",
    "        ]\n",
    "        if len(self.segments) > 1 and len(self.segments[-2]) != len(self.segments[-1]): \n",
    "            self.segments[-2] = np.concatenate((self.segments[-2], self.segments[-1]))\n",
    "            self.segments.pop()  # Remove the now redundant last segment\n",
    "    \n",
    "    def segment_audio_using_other_method(self):\n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "        # Load the audio file using moviepy\n",
    "        audio_clip = AudioFileClip(self.file_path)\n",
    "        duration = audio_clip.duration  # Total duration in seconds\n",
    "\n",
    "        # Duration of a 30-second segment in seconds\n",
    "        segment_length = 30  \n",
    "        start_time = 0\n",
    "        clip_number = 1\n",
    "\n",
    "        while start_time < duration:\n",
    "            end_time = min(start_time + segment_length, duration)\n",
    "\n",
    "            # Extract the segment\n",
    "            segment = audio_clip.subclip(start_time, end_time)\n",
    "\n",
    "            # Save the segment to a file\n",
    "            new_filename = f\"clip{clip_number}.mp3\"\n",
    "            segment.write_audiofile(os.path.join(self.output_folder, new_filename))\n",
    "\n",
    "            # Prepare for the next segment\n",
    "            start_time = end_time\n",
    "            clip_number += 1\n",
    "        \n",
    "    def extract_features_new_method(self):\n",
    "        \n",
    "        file_paths = [os.path.join(self.output_folder, f) for f in os.listdir(self.output_folder) if f.endswith('.mp3')]\n",
    "        \n",
    "        # Compute chroma, ZCR, RMS, and spectral features\n",
    "        for segment in file_paths:\n",
    "            segment_loaded, self.sr = librosa.load(segment, sr=None)\n",
    "            self.computed = self.compute_audio(segment_loaded, self.sr)\n",
    "            print('this is self.computed:', type(self.computed.y))\n",
    "            print(self.computed.y)\n",
    "            chroma = self.computed.compute_chroma_mean()\n",
    "            zcr = self.computed.compute_zcr_mean()\n",
    "            rms = self.computed.compute_rms_energy()\n",
    "            centroid = self.computed.compute_spectral_centroid_mean()\n",
    "            bandwidth = self.computed.compute_spectral_bandwidth_mean()\n",
    "            rolloff = self.computed.compute_spectral_rolloff_mean()\n",
    "            self.features.append(np.hstack([chroma, zcr, rms, centroid, bandwidth, rolloff]))\n",
    "        \n",
    "    def extract_features(self):\n",
    "        # Compute chroma, ZCR, RMS, and spectral features\n",
    "        for segment in self.segments:\n",
    "            self.computed = self.compute_audio(segment, self.sr)\n",
    "            #print('ewwww', self.computed.y)\n",
    "            chroma = self.computed.compute_chroma_mean()\n",
    "            zcr = self.computed.compute_zcr_mean()\n",
    "            rms = self.computed.compute_rms_energy()\n",
    "            centroid = self.computed.compute_spectral_centroid_mean()\n",
    "            bandwidth = self.computed.compute_spectral_bandwidth_mean()\n",
    "            rolloff = self.computed.compute_spectral_rolloff_mean()\n",
    "            self.features.append(np.hstack([chroma, zcr, rms, centroid, bandwidth, rolloff]))\n",
    "\n",
    "    def normalize_features(self):\n",
    "        # Normalize the features with MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        self.features = scaler.fit_transform(self.features)\n",
    "\n",
    "    def classify_segments(self):\n",
    "        # Load model and classify segments\n",
    "        model = load_model('deep_ann_model_2025.h5')\n",
    "        arabic_maqam_mapping = {\n",
    "            0: 'بيات',\n",
    "            1: 'حجاز',\n",
    "            2: 'راست',\n",
    "            3: 'سيكاه',\n",
    "            4: 'صبا',\n",
    "            5: 'عجم',\n",
    "            6: 'كرد',\n",
    "            7: 'نهاوند'\n",
    "        }\n",
    "        english_maqam_mapping = {\n",
    "            0: 'Bayat',\n",
    "            1: 'Hejaz',\n",
    "            2: 'Rast',\n",
    "            3: 'Seekah',\n",
    "            4: 'Saba',\n",
    "            5: 'Ajam',\n",
    "            6: 'Kurd',\n",
    "            7: 'Nahawand' # there was an error here\n",
    "        }\n",
    "        translate = {\n",
    "            'بيات': 'Bayat',\n",
    "            'حجاز': 'Hejaz',\n",
    "            'راست': 'Rast',\n",
    "            'سيكاه': 'Seekah',\n",
    "            'صبا': 'Saba',\n",
    "            'عجم': 'Ajam',\n",
    "            'كرد': 'Kurd',\n",
    "            'نهاوند': 'Nahawand'\n",
    "        }\n",
    "        self.predictions = [\n",
    "            np.argmax(model.predict(np.expand_dims(feature, axis=0)))\n",
    "            for feature in self.features\n",
    "        ]\n",
    "        self.predictions_mapped = [english_maqam_mapping[pred] for pred in self.predictions]\n",
    "\n",
    "\n",
    "    def post_process_predictions(self):\n",
    "        # Apply rules for outliers and maqam switches\n",
    "        pass\n",
    "    \n",
    "    def voting_system(self):\n",
    "        np_list_predictions = np.array(self.predictions_mapped)\n",
    "        unique, counts = np.unique(np_list_predictions, return_counts=True)\n",
    "        self.most_frequent = unique[np.argmax(counts)]\n",
    "        return self.most_frequent\n",
    "\n",
    "    def generate_summary(self):\n",
    "        # Combine results into a structured summary\n",
    "        summary = []\n",
    "        start_time = 0\n",
    "        for i, maqam in enumerate(self.predictions_mapped):\n",
    "            if i == 0 or maqam != self.predictions_mapped[i - 1]:\n",
    "                if i > 0:\n",
    "                    summary[-1]['end'] = f\"{start_time // 60:02}:{start_time % 60:02}\"\n",
    "                summary.append({\n",
    "                    'maqam': maqam,\n",
    "                    'start': f\"{start_time // 60:02}:{start_time % 60:02}\",\n",
    "                    'end': None\n",
    "                })\n",
    "            start_time += 30\n",
    "        if summary:\n",
    "            summary[-1]['end'] = f\"{start_time // 60:02}:{start_time % 60:02}\"\n",
    "        self.summary = summary\n",
    "\n",
    "        \n",
    "\n",
    "    def clear_temp(self):\n",
    "        shutil.rmtree(self.output_folder)\n",
    "        \n",
    "\n",
    "    def process(self):\n",
    "        # High-level method to run all steps in sequence\n",
    "        self.check_format()\n",
    "        self.convert_video_to_audio()\n",
    "        self.segment_audio()\n",
    "        self.extract_features()\n",
    "        self.normalize_features()\n",
    "        self.classify_segments()\n",
    "        self.voting_system()\n",
    "        return self.most_frequent\n",
    "\n",
    "    \n",
    "    def process_mew(self):\n",
    "        # High-level method to run all steps in sequence\n",
    "        self.check_format()\n",
    "        self.convert_video_to_audio()\n",
    "        self.segment_audio_using_other_method()\n",
    "        self.extract_features_new_method()\n",
    "        self.normalize_features()\n",
    "        self.classify_segments()\n",
    "        self.voting_system()\n",
    "        self.clear_temp()\n",
    "        return self.most_frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91665d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    file_path = 'surah55-Copy1.mp4'\n",
    "    processor = AudioProcessor(file_path, compute_audio)\n",
    "    summary = processor.process()\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1279b6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in surah55-Copy1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip3.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip4.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip5.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip6.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip7.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip8.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip9.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip10.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip11.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip12.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip13.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip14.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip15.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip16.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip17.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip18.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip19.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip20.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip21.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temporary/clip22.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[-0.27044028 -0.32897973 -0.2781739  ...  0.23899001  0.27471447\n",
      "  0.21442136]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.19285628 0.25212148 0.19382603 ... 0.17136462 0.1319382  0.07277904]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[ 0.02797854  0.01124231 -0.00158575 ... -0.00217554 -0.00277983\n",
      " -0.0023978 ]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[-0.15217018 -0.17264733 -0.09977181 ...  0.04036367  0.08610441\n",
      "  0.0860716 ]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[-0.15555495 -0.21261916 -0.20583439 ...  0.375535    0.41924697\n",
      "  0.3045613 ]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[ 0.06537426  0.08215514  0.07181429 ... -0.28735858 -0.35122964\n",
      " -0.27935758]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.2419265  0.24942371 0.12912089 ... 0.3590496  0.38915297 0.29118752]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.08761727 0.14697751 0.16336717 ... 0.41428155 0.431162   0.30846047]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.27250546 0.337222   0.24710965 ... 0.         0.         0.        ]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[ 0.00521795 -0.00561495 -0.03859805 ... -0.09185711 -0.07317416\n",
      " -0.03932633]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[-0.00095471 -0.00129236  0.00178838 ...  0.13796374  0.13075113\n",
      "  0.08550209]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[ 0.01779132 -0.01007389 -0.05712984 ...  0.46647096  0.5093218\n",
      "  0.3700007 ]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.06740309 0.07137013 0.0546998  ... 0.1493954  0.13184565 0.0815024 ]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.04431272 0.0414051  0.01972176 ... 0.04866803 0.04655936 0.03180716]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[ 0.          0.          0.         ... -0.15934688 -0.10088155\n",
      " -0.03599044]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[ 0.02403917  0.02544722  0.01720073 ... -0.14115521 -0.18826757\n",
      " -0.15892412]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[ 0.26509064  0.37604043  0.33452383 ... -0.20093963 -0.22850642\n",
      " -0.16850267]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.05758194 0.08792682 0.11650202 ... 0.09904703 0.08273619 0.05313467]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[-0.03505537 -0.01809222  0.0100981  ...  0.06403364  0.07651043\n",
      "  0.06197102]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.24142358 0.27504033 0.17895043 ... 0.23899817 0.2935667  0.23306195]\n",
      "this is self.computed: <class 'numpy.ndarray'>\n",
      "[0.40478584 0.48980695 0.3710365  ... 0.0193383  0.03225807 0.02887968]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 08:41:09.824559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/videos/myenv_new/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2025-03-04 08:41:09.824614: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-03-04 08:41:09.824641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-29-3): /proc/driver/nvidia/version does not exist\n",
      "2025-03-04 08:41:09.825041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Bayat\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    file_path = 'surah55-Copy1.mp4'\n",
    "    processor = AudioProcessor(file_path, compute_audio)\n",
    "    summary = processor.process_mew()\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96de974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بيات\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f986e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your mom\n"
     ]
    }
   ],
   "source": [
    "print('your mom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f678e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
